{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general python libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import convolve\n",
    "from empatches import EMPatches\n",
    "\n",
    "# Import the GDAL module from the osgeo package\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GDT_Byte\n",
    "\n",
    "# Import necessary functions and classes from Keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112389ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for normalisation of vegetation indices\n",
    "def post_idx_calc(index, normalise):\n",
    "    # Replace nan with zero and inf with finite numbers\n",
    "    idx = np.nan_to_num(index)\n",
    "    if normalise:\n",
    "        return cv2.normalize(\n",
    "            idx, None, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    else:\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate vegetation indices\n",
    "def calculate_veg_indices(input_img):\n",
    "# Extract the all channels from the input image\n",
    "    RedEdge = input_img[:, :, 3]\n",
    "    nir = input_img[:, :, 4]\n",
    "    red = input_img[:, :, 2]\n",
    "    green = input_img[:, :, 1]\n",
    "    blue = input_img[:, :, 0]\n",
    "\n",
    "# Define all the vegetation indices\n",
    "    # Calculate vegetation indices\n",
    "    ndvi = post_idx_calc((nir - red) / (nir + red),normalise=False)\n",
    "    dvi = post_idx_calc((nir - red),normalise=False)\n",
    "    tvi = post_idx_calc((60*(nir - green)) - (100 * (red - green)),normalise=False)\n",
    "    gdvi = post_idx_calc((nir - green),normalise=False)\n",
    "    endvi = post_idx_calc(((nir + green) - (2 * blue)) / ((nir + green) + (2 * blue)),normalise=False)\n",
    "\n",
    "    veg_indices = np.stack((ndvi, dvi, tvi, gdvi, endvi), axis=2)\n",
    "\n",
    "    return veg_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the width and height of an image using GDAL (If required)\n",
    "def get_image_dimensions(file_path):\n",
    "    ds = gdal.Open(file_path)\n",
    "    if ds is not None:\n",
    "        width = ds.RasterXSize\n",
    "        height = ds.RasterYSize\n",
    "        return width, height\n",
    "    return None, None\n",
    "\n",
    "# Minimum width and height for filtering\n",
    "min_width = 256\n",
    "min_height = 256\n",
    "max_width = 2000\n",
    "max_height = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map labels to colors\n",
    "def map_labels_to_colors(prediction):\n",
    "    color_mapping = {\n",
    "        0: [0, 255, 0],  # Green for ID 0\n",
    "        1: [255, 0, 0],  # Red for ID 1\n",
    "    }\n",
    "    colored_image = np.zeros((prediction.shape[0], prediction.shape[1], 3), dtype=np.uint8)\n",
    "    for label, color in color_mapping.items():\n",
    "        mask = prediction == label\n",
    "        colored_image[mask] = color\n",
    "    return colored_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711606c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory with input images and respective masks\n",
    "root_data_folder = r'/home/n10837647/pandanus_classification'\n",
    "root_image_folder = r'/home/n10837647/pandanus_classification/msi_image_mask_rois/testing'\n",
    "root_model_folder =os.path.join(root_data_folder, 'model&outcomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unet model\n",
    "unet_model = load_model(os.path.join(root_model_folder,'save_best_model.hdf5'))\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e74ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multispectral images\n",
    "images = []\n",
    "input_img_folder = os.path.join(root_image_folder, 'msi_rois')\n",
    "\n",
    "# Retrieve all image\n",
    "img_files = [file for file in os.listdir(input_img_folder) if file.endswith(\".tif\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d12808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "patch_size = 256\n",
    "total_files = len(img_files)\n",
    "ignored_files = 0\n",
    "\n",
    "for i in range(len(img_files)):\n",
    "    img_file = os.path.join(input_img_folder, img_files[i])\n",
    "    img_ds = gdal.Open(img_file)\n",
    "    input_img = np.array(img_ds.ReadAsArray(), dtype=np.float32)\n",
    "    input_img = np.transpose(input_img, (1, 2, 0))\n",
    "    input_img = exposure.equalize_hist(input_img)\n",
    "\n",
    "    veg_indices = calculate_veg_indices(input_img)\n",
    "    input_img = np.concatenate((input_img, veg_indices), axis=2)\n",
    "\n",
    "    # Check the image size\n",
    "    if input_img.shape[0] < patch_size or input_img.shape[1] < patch_size:\n",
    "        ignored_files += 1\n",
    "        continue\n",
    "#----------------------------------------------------------------------#\n",
    "    # Check if both width and height are greater than patch_size\n",
    "    if input_img.shape[0] >= patch_size and input_img.shape[1] >= patch_size:\n",
    "        emp = EMPatches()\n",
    "        img_patches, indices = emp.extract_patches(input_img, patchsize=patch_size, overlap=0.3)\n",
    "\n",
    "        # Create patches of the desired size\n",
    "        resized_patches = []\n",
    "        for patch in img_patches:\n",
    "            patch_height, patch_width, _ = patch.shape\n",
    "            if patch_height < patch_size or patch_width < patch_size:\n",
    "                target_height = max(patch_height, patch_size)\n",
    "                target_width = max(patch_width, patch_size)\n",
    "                resized_patch = np.zeros((target_height, target_width, patch.shape[2]), dtype=np.float32)\n",
    "                resized_patch[:patch_height, :patch_width, :] = patch\n",
    "            else:\n",
    "                resized_patch = patch[:patch_size, :patch_size, :]\n",
    "            resized_patches.append(resized_patch)\n",
    "\n",
    "        img_patches_processed = unet_model.predict(np.array(resized_patches))\n",
    "        merged_img_patches_processed = emp.merge_patches(img_patches_processed, indices, mode='min')\n",
    "\n",
    "        # Retrieve geo information\n",
    "        geotransform = img_ds.GetGeoTransform()\n",
    "        projection = img_ds.GetProjection()\n",
    "\n",
    "        # Reshape the predicted image to 2D\n",
    "        pred_image = np.argmax(merged_img_patches_processed, axis=-1)\n",
    "\n",
    "        # Create a new .dat and .hdr file for the predicted image\n",
    "        driver = gdal.GetDriverByName('ENVI')\n",
    "        pred_image_file = os.path.splitext(img_files[i])[0] + '_pred.dat'\n",
    "\n",
    "        # Define the path to the \"prediction\" folder\n",
    "        prediction_folder = os.path.join(root_model_folder, 'prediction')\n",
    "\n",
    "        # Check if the \"prediction\" folder exists, and create it if it doesn't\n",
    "        if not os.path.exists(prediction_folder):\n",
    "            os.makedirs(prediction_folder)\n",
    "\n",
    "        pred_image_path = os.path.join(prediction_folder, pred_image_file)\n",
    "\n",
    "        # Create the output GDAL dataset\n",
    "        pred_image_ds = driver.Create(pred_image_path, pred_image.shape[1], pred_image.shape[0], 1, gdal.GDT_Byte)\n",
    "\n",
    "        # Write the predicted image data to the new file\n",
    "        pred_image_ds.GetRasterBand(1).WriteArray(pred_image)\n",
    "\n",
    "        # Add spatial reference information\n",
    "        pred_image_ds.SetGeoTransform(geotransform)\n",
    "        pred_image_ds.SetProjection(projection)\n",
    "\n",
    "        # Close the files\n",
    "        pred_image_ds = None\n",
    "\n",
    "        print(f\"Prediction.dat saved for image {img_files[i]}\")\n",
    "#----------------------------------------------------------------------#\n",
    "        # Map labels to colors for the .tif file\n",
    "        colored_prediction = map_labels_to_colors(pred_image)\n",
    "\n",
    "        # Create the directory for the .tif file if it doesn't exist\n",
    "        tif_file_directory = os.path.join(root_model_folder, 'prediction')\n",
    "        if not os.path.exists(tif_file_directory):\n",
    "            os.makedirs(tif_file_directory)\n",
    "\n",
    "        # Create a new .tif file for the colored prediction image (with color mapping)\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        pred_image_file = os.path.splitext(img_files[i])[0] + '_pred.tif'\n",
    "        tif_file_path = os.path.join(tif_file_directory, pred_image_file)\n",
    "        pred_image_ds = driver.Create(tif_file_path, pred_image.shape[1], pred_image.shape[0], 3, GDT_Byte)\n",
    "        pred_image_ds.GetRasterBand(1).WriteArray(colored_prediction[:, :, 0])\n",
    "        pred_image_ds.GetRasterBand(2).WriteArray(colored_prediction[:, :, 1])\n",
    "        pred_image_ds.GetRasterBand(3).WriteArray(colored_prediction[:, :, 2])\n",
    "        pred_image_ds.SetGeoTransform(geotransform)\n",
    "        pred_image_ds.SetProjection(projection)\n",
    "        pred_image_ds = None\n",
    "        print(f\"prediction.tif saved for image {img_files[i]}\")\n",
    "#----------------------------------------------------------------------#\n",
    "print(f\"Total MS ROIs: {total_files}\")\n",
    "print(f\"Ignored MS ROIs: {ignored_files}\")\n",
    "\n",
    "print(\"All predictions saved.\")\n",
    "#-------------------------xxxxxx---------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
