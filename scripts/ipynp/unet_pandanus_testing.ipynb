{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general python libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "# Import the GDAL module from the osgeo package\n",
    "from osgeo import gdal\n",
    "\n",
    "# Import necessary functions from scikit-learn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Import necessary functions and classes from Keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84febc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for normalisation of vegetation indices\n",
    "def post_idx_calc(index, normalise):\n",
    "    # Replace nan with zero and inf with finite numbers\n",
    "    idx = np.nan_to_num(index)\n",
    "    if normalise:\n",
    "        return cv2.normalize(\n",
    "            idx, None, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    else:\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d679fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate vegetation indices\n",
    "def calculate_veg_indices(input_img):\n",
    "# Extract the all channels from the input image\n",
    "    RedEdge = input_img[:, :, 3]\n",
    "    nir = input_img[:, :, 4]\n",
    "    red = input_img[:, :, 2]\n",
    "    green = input_img[:, :, 1]\n",
    "    blue = input_img[:, :, 0]\n",
    "\n",
    "# Define all the vegetation indices\n",
    "    # Calculate vegetation indices\n",
    "    ndvi = post_idx_calc((nir - red) / (nir + red),normalise=False)\n",
    "    dvi = post_idx_calc((nir - red),normalise=False)\n",
    "    tvi = post_idx_calc((60*(nir - green)) - (100 * (red - green)),normalise=False)\n",
    "    gdvi = post_idx_calc((nir - green),normalise=False)\n",
    "    endvi = post_idx_calc(((nir + green) - (2 * blue)) / ((nir + green) + (2 * blue)),normalise=False)\n",
    "\n",
    "    veg_indices = np.stack((ndvi, dvi, tvi, gdvi, endvi), axis=2)\n",
    "\n",
    "    return veg_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96097c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the width and height of an image using GDAL (If required)\n",
    "def get_image_dimensions(file_path):\n",
    "    ds = gdal.Open(file_path)\n",
    "    if ds is not None:\n",
    "        width = ds.RasterXSize\n",
    "        height = ds.RasterYSize\n",
    "        return width, height\n",
    "    return None, None\n",
    "\n",
    "# Minimum width and height for filtering\n",
    "min_width = 256\n",
    "min_height = 256\n",
    "max_width = 2000\n",
    "max_height = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f858b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tile size and overlap percentage\n",
    "tile_size = 256\n",
    "overlap = int(tile_size * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory with input images and respective masks\n",
    "root_data_folder = r'/home/n10837647/pandanus_classification'\n",
    "root_image_folder = r'/home/n10837647/pandanus_classification/msi_image_mask_rois/testing'\n",
    "root_model_folder =os.path.join(root_data_folder, 'model&outcomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unet model\n",
    "unet_model = load_model(os.path.join(root_model_folder,'save_best_model.hdf5'))\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the tiled images and masks\n",
    "image_patches = []\n",
    "mask_patches = []\n",
    "\n",
    "# Define a function to get the width and height of an image using GDAL\n",
    "def get_image_dimensions(file_path):\n",
    "    ds = gdal.Open(file_path)\n",
    "    if ds is not None:\n",
    "        width = ds.RasterXSize\n",
    "        height = ds.RasterYSize\n",
    "        return width, height\n",
    "    return None, None\n",
    "\n",
    "# Specify the folder paths for images and masks\n",
    "image_folder_path = os.path.join(root_image_folder, 'msi_rois')\n",
    "mask_folder_path = os.path.join(root_image_folder, 'msi_mask_rois')\n",
    "\n",
    "# Filter image and mask files based on dimensions\n",
    "filtered_image_files = []\n",
    "filtered_mask_files = []\n",
    "\n",
    "input_img_folder = os.path.join(root_image_folder, 'msi_rois')\n",
    "input_mask_folder = os.path.join(root_image_folder, 'msi_mask_rois')\n",
    "\n",
    "img_files = [file for file in os.listdir(input_img_folder) if file.endswith(\".tif\")]\n",
    "mask_files = [file for file in os.listdir(input_mask_folder) if file.endswith(\".tif\")]\n",
    "\n",
    "# Iterate through the image files\n",
    "for img_file in img_files:\n",
    "    img_path = os.path.join(image_folder_path, img_file)\n",
    "    img_width, img_height = get_image_dimensions(img_path)\n",
    "    \n",
    "    if img_width is not None and img_height is not None:\n",
    "        if min_width <= img_width <= max_width and min_height <= img_height <= max_height:\n",
    "            filtered_image_files.append(img_path)\n",
    "\n",
    "# Iterate through the mask files\n",
    "for mask_file in mask_files:\n",
    "    mask_path = os.path.join(mask_folder_path, mask_file)\n",
    "    mask_width, mask_height = get_image_dimensions(mask_path)\n",
    "    \n",
    "    if mask_width is not None and mask_height is not None:\n",
    "        if min_width <= mask_width <= max_width and min_height <= mask_height <= max_height:\n",
    "            filtered_mask_files.append(mask_path)\n",
    "\n",
    "# Print the number of filtered image and mask files\n",
    "print(f\"Number of filtered image files: {len(filtered_image_files)}\")\n",
    "print(f\"Number of filtered mask files: {len(filtered_mask_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the filtered files to ensure consistent ordering\n",
    "filtered_image_files.sort()\n",
    "filtered_mask_files.sort()\n",
    "\n",
    "for i in range(len(filtered_image_files)):\n",
    "    img_file = os.path.basename(filtered_image_files[i])  # Get the file name without the path\n",
    "    mask_file = os.path.basename(filtered_mask_files[i])  # Get the file name without the path\n",
    "    \n",
    "    ds_img = gdal.Open(filtered_image_files[i])\n",
    "    ds_mask = gdal.Open(filtered_mask_files[i])\n",
    "    width = ds_img.RasterXSize\n",
    "    height = ds_img.RasterYSize\n",
    "\n",
    "    # Calculate the number of tiles in the image\n",
    "    num_tiles_x = (width - tile_size) // (tile_size - overlap) + 1\n",
    "    num_tiles_y = (height - tile_size) // (tile_size - overlap) + 1\n",
    "\n",
    "    for y in range(num_tiles_y):\n",
    "        for x in range(num_tiles_x):\n",
    "            # Calculate the tile coordinates\n",
    "            x_start = x * (tile_size - overlap)\n",
    "            y_start = y * (tile_size - overlap)\n",
    "            x_end = x_start + tile_size\n",
    "            y_end = y_start + tile_size\n",
    "\n",
    "            # Extract the image tile\n",
    "            input_bands = 5  # Number of input bands\n",
    "            input_img = np.array([ds_img.GetRasterBand(j + 1).ReadAsArray(x_start, y_start, tile_size, tile_size) for j in range(input_bands)])\n",
    "            input_img = np.transpose(input_img, (1, 2, 0))\n",
    "            input_img = exposure.equalize_hist(input_img)\n",
    "            \n",
    "            veg_indices = calculate_veg_indices(input_img)\n",
    "            input_img = np.concatenate((input_img, veg_indices), axis=2)\n",
    "\n",
    "            input_mask = ds_mask.GetRasterBand(1).ReadAsArray(x_start, y_start, tile_size, tile_size).astype(int)\n",
    "           \n",
    "            image_patches.append(input_img)\n",
    "            mask_patches.append(input_mask)\n",
    "\n",
    "    print(f\"Processed image: {img_file} --> Processed mask: {mask_file}\")\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "image_patches = np.array(image_patches)\n",
    "mask_patches = np.array(mask_patches)\n",
    "\n",
    "# Print the shape of the arrays\n",
    "print(\"image_patches.shape: {}\".format(image_patches.shape))\n",
    "print(\"mask_patches.shape: {}\".format(mask_patches.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the print results to a text file\n",
    "output_file = os.path.join(root_model_folder, 'testing samples.txt')\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(\"image_patches.shape: {}\\n\".format(image_patches.shape))\n",
    "    file.write(\"mask_patches.shape: {}\\n\".format(mask_patches.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25278a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the mask_patches data and converts it into a categorical representation. \n",
    "mask_patches_to_categorical = to_categorical(mask_patches, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion_matrix and Classification_report\n",
    "#----------------#\n",
    "# Confusion_matrix\n",
    "#----------------#\n",
    "\n",
    "# Predict on the validation data\n",
    "y_pred = unet_model.predict(image_patches)\n",
    "\n",
    "# Convert the predicted and true masks to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
    "y_test_classes = np.argmax(mask_patches_to_categorical, axis=-1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_classes.ravel(), y_pred_classes.ravel())\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)\n",
    "# #------------------------------------------------------------------#\n",
    "# Plot the confusion matrix \n",
    "labels = ['Background','Pandanous']\n",
    "# Plot the confusion matrix using heatmap()\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('confusion matrix_heatmap')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.savefig(os.path.join(root_model_folder, 'CM_heatmap_validation.png'), bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved testing_confusion matrix_heatmap')\n",
    "#------------------------------------------------------------------#\n",
    "#---------------------#\n",
    "# classification report\n",
    "#---------------------#\n",
    "cr = classification_report(y_test_classes.ravel(), y_pred_classes.ravel(), target_names=['Background','Pandanous'])\n",
    "# Print the classification report\n",
    "print(cr)\n",
    "#------------------------------------------------------------------#\n",
    "# Export confusion matrix and classification report as .txt\n",
    "file_path = os.path.join(root_model_folder, 'model testing performance report.txt')\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(\"Confusion Matrix:\\n\")\n",
    "    file.write(str(cm))\n",
    "    file.write(\"\\n\\n\")\n",
    "    file.write(\"Classification Report:\\n\")\n",
    "    file.write(cr)\n",
    "print('Saved classification_and_confusion_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IOU\n",
    "# Calculate and save IoU for each class\n",
    "class_iou = []\n",
    "with open(file_path, 'a') as file:\n",
    "    file.write(\"\\n\\nIoU Results:\\n\")\n",
    "    for i in range(2):\n",
    "        true_class = (y_test_classes == i)\n",
    "        pred_class = (y_pred_classes == i)\n",
    "        intersection = np.sum(true_class * pred_class)\n",
    "        union = np.sum(true_class) + np.sum(pred_class) - intersection\n",
    "        iou = intersection / union\n",
    "        class_iou.append(iou)\n",
    "        file.write(\"IoU for class {}: {:.2f}\\n\".format(i+1, iou))\n",
    "        print(\"IoU for class {}: {:.2f}\".format(i+1, iou))\n",
    "# Calculate and save average IoU\n",
    "average_iou = np.mean(class_iou)\n",
    "with open(file_path, 'a') as file:\n",
    "    file.write(\"Average IoU: {:.2f}\".format(average_iou))\n",
    "    print(\"Average IoU: {:.2f}\".format(average_iou))\n",
    "print('Saved IoU results')\n",
    "#-------------------------xxxxxx---------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
